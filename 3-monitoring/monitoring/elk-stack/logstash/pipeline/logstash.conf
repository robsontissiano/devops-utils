# Main Logstash Pipeline Configuration

input {
  # Beats input (Filebeat, Metricbeat, etc.)
  beats {
    port => 5044
    codec => json
  }

  # TCP input for direct log shipping
  tcp {
    port => 5000
    codec => json_lines
  }

  # UDP input for syslog
  udp {
    port => 5000
    codec => json_lines
  }
}

filter {
  # Parse timestamp if present
  if [timestamp] {
    date {
      match => [ "timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss", "dd/MMM/yyyy:HH:mm:ss Z" ]
      target => "@timestamp"
    }
  }

  # Add hostname if not present
  if ![host][name] {
    mutate {
      add_field => { "[host][name]" => "%{host}" }
    }
  }

  # Parse log level
  if [message] =~ /ERROR|WARN|INFO|DEBUG|TRACE/ {
    grok {
      match => { "message" => "%{LOGLEVEL:log_level}" }
    }
  }

  # Add tags based on log type
  if [fields][log_type] {
    mutate {
      add_tag => [ "%{[fields][log_type]}" ]
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => [ "[beat]", "[prospector]", "[input]", "[fields][log_type]" ]
  }
}

output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOSTS:elasticsearch:9200}"]
    index => "logs-%{+YYYY.MM.dd}"
    document_type => "_doc"
  }

  # Output to stdout for debugging (comment out in production)
  stdout {
    codec => rubydebug
  }
}

